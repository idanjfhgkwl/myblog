{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dtxgqub_0iR"
   },
   "source": [
    "---\n",
    "title: \"ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법\"\n",
    "categories:\n",
    "  - study\n",
    "output: \n",
    "  html_document:\n",
    "    keep_md: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyXtp3thBO6t"
   },
   "source": [
    "# ML 모델 을 평가하기 위한 올바른 측정 항목을 선택하는 방법\n",
    "(How to Choose Right Metric for Evaluating ML Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouum6MF4B_NQ"
   },
   "source": [
    "## 도입부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBAhIRd6BiFA"
   },
   "source": [
    "https://www.kaggle.com/vipulgandhi/how-to-choose-right-metric-for-evaluating-ml-model\n",
    "\n",
    "이 [Scikit-learn 페이지](https://scikit-learn.org/stable/modules/model_evaluation.html)는 훌륭한 참조를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2ajtOQUCFIY"
   },
   "source": [
    "일반적인 기능 엔지니어링, 선택, 모델 구현을 수행하고 확률 또는 클래스 형태로 출력을 얻은 후 다음 단계는 테스트 데이터 세트를 사용하여 일부 메트릭을 기반으로 모델이 얼마나 효과적인지 확인하는 것입니다. 메트릭은 모델의 성능을 설명합니다.  \n",
    "<br>\n",
    "모델은 정확도 _ 점수라는 메트릭을 사용하여 평가할 때 만족스러운 결과를 제공 할 수 있지만 logarithmic_loss와 같은 다른 메트릭 또는 다른 이러한 메트릭에 대해 평가할 때 좋지 않은 결과를 제공 할 수 있습니다. 따라서 기계 학습 모델을 평가하기 위해 올바른 메트릭을 선택하는 것이 매우 중요합니다.  \n",
    "<br>\n",
    "측정 항목 선택은 기계 학습 알고리즘의 성능을 측정하고 비교하는 방법에 영향을줍니다. 결과에서 다른 특성의 중요성에 가중치를 부여하는 방법에 영향을줍니다.  \n",
    "<br>\n",
    "**분류 메트릭**\n",
    "- 정확성.\n",
    "- 대수 손실.\n",
    "- ROC, AUC.\n",
    "- 혼란 매트릭스.\n",
    "- 분류 보고서.\n",
    "\n",
    "**회귀 지표**\n",
    "- 평균 절대 오차.\n",
    "- 평균 제곱 오차.\n",
    "- 평균 제곱근 오차.\n",
    "- 루트 평균 제곱 로그 오류.\n",
    "- R 광장.\n",
    "- R 제곱을 조정했습니다.\n",
    "\n",
    "**분류 문제**에서는 , 우리는 (자신이 생성 출력의 종류에 따라) 알고리즘의 두 가지 유형을 사용\n",
    "- **클래스 출력** : SVM 및 KNN과 같은 알고리즘은 클래스 출력을 생성합니다. 예를 들어, 이진 분류 문제에서 출력은 0 또는 1입니다. SKLearn의 / 기타 알고리즘은 이러한 클래스 출력을 확률로 변환 할 수 있습니다.\n",
    "- **확률 출력** : 로지스틱 회귀, 랜덤 포레스트, 그라디언트 부스팅, Adaboost 등과 같은 알고리즘은 확률 출력을 제공합니다. 확률 출력은 임계 확률을 생성하여 클래스 출력으로 변환 할 수 있습니다.\n",
    "\n",
    "회귀 문제에서 출력은 본질적으로 항상 연속적이며 추가 처리가 필요하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c0wC8WjDSy6"
   },
   "source": [
    "## 분류 메트릭\n",
    "(Classification Metrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVf6AXElDgtJ"
   },
   "source": [
    "- 데이터 세트 : 피마 인디언 당뇨병 예측.  \n",
    "- 평가 알고리즘 : 로지스틱 회귀, SGDClassifier, RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7vx_XzVEW2A",
    "outputId": "b0bd3df5-cf79-4c3d-e9de-0952128b978e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n",
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks/python_basic/kaggle_how-to-choose-right-metric-for-evaluating-ml-model_vipulgandhi/data\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive # 패키지 불러오기 \n",
    "from os.path import join  \n",
    "\n",
    "# 구글 드라이브 마운트\n",
    "ROOT = \"/content/drive\"     # 드라이브 기본 경로\n",
    "print(ROOT)                 # print content of ROOT (Optional)\n",
    "drive.mount(ROOT)           # 드라이브 기본 경로 \n",
    "\n",
    "# 프로젝트 파일 생성 및 다운받을 경로 이동\n",
    "MY_GOOGLE_DRIVE_PATH = 'My Drive/Colab Notebooks/python_basic/kaggle_how-to-choose-right-metric-for-evaluating-ml-model_vipulgandhi/data'\n",
    "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
    "print(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLXic-KOE4lx",
    "outputId": "93ad47a2-807c-4465-cd31-380493f1be54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/python_basic/kaggle_how-to-choose-right-metric-for-evaluating-ml-model_vipulgandhi/data\n"
     ]
    }
   ],
   "source": [
    "%cd \"{PROJECT_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVTVl3atErwp",
    "outputId": "979694aa-6b14-41e8-c54f-feec0f188d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NZ2gw1qPDw4-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "diabetes_data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "X =  diabetes_data.drop([\"Outcome\"],axis = 1)\n",
    "y = diabetes_data[\"Outcome\"]\n",
    "\n",
    "# 훈련 세트를 사용하여 다양한 하이퍼 파라미터로 여러 모델을 훈련하고 검증 세트에서 가장 잘 수행되는 모델과 하이퍼 파라미터를 선택합니다.\n",
    "# 모델 유형과 하이퍼 파라미터가 선택되면 전체 훈련 세트에서 이러한 하이퍼 파라미터를 사용하여 최종 모델을 훈련시키고 일반화 된 오류는 테스트 세트에서 최종적으로 측정됩니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 56)\n",
    "\n",
    "# StratifiedKFold 클래스는 계층화 된 샘플링을 수행하여 각 클래스의 대표 비율을 포함하는 폴드를 생성합니다.\n",
    "cv = StratifiedKFold(n_splits=10, shuffle = False, random_state = 76)\n",
    "\n",
    "# 로지스틱 회귀\n",
    "clf_logreg = LogisticRegression()\n",
    "# 적합 모델\n",
    "clf_logreg.fit(X_train, y_train)\n",
    "# 검증 세트에 대한 클래스 예측을합니다.\n",
    "y_pred_class_logreg = cross_val_predict(clf_logreg, X_train, y_train, cv = cv)\n",
    "# 클래스 1에 대한 예측 확률, 양성 클래스의 확률\n",
    "y_pred_prob_logreg = cross_val_predict(clf_logreg, X_train, y_train, cv = cv, method=\"predict_proba\")\n",
    "y_pred_prob_logreg_class1 = y_pred_prob_logreg[:, 1]\n",
    "\n",
    "# SGD 분류기\n",
    "clf_SGD = SGDClassifier()\n",
    "# 적합 모델\n",
    "clf_SGD.fit(X_train, y_train)\n",
    "# 검증 세트에 대한 클래스 예측을합니다.\n",
    "y_pred_class_SGD = cross_val_predict(clf_SGD, X_train, y_train, cv = cv)\n",
    "# 클래스 1에 대한 예측 확률\n",
    "y_pred_prob_SGD = cross_val_predict(clf_SGD, X_train, y_train, cv = cv, method=\"decision_function\")\n",
    "\n",
    "# 랜덤 포레스트 분류기\n",
    "clf_rfc = RandomForestClassifier()\n",
    "# 적합 모델\n",
    "clf_rfc.fit(X_train, y_train)\n",
    "# 검증 세트에 대한 클래스 예측을합니다.\n",
    "y_pred_class_rfc = cross_val_predict(clf_rfc, X_train, y_train, cv = cv)\n",
    "# 클래스 1에 대한 예측 확률\n",
    "y_pred_prob_rfc = cross_val_predict(clf_rfc, X_train, y_train, cv = cv, method=\"predict_proba\")\n",
    "y_pred_prob_rfc_class1 = y_pred_prob_rfc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87yl98VIFr7X"
   },
   "source": [
    "**빠른 참고** : SkLearn의 \"predict_log_proba\"는 확률의 로그를 제공합니다. 확률이 매우 작아 질 수 있으므로 종종 더 편리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApSM9_dFFy-R"
   },
   "source": [
    "### Null 정확도\n",
    "(Null accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVc6l0vPF4Fx"
   },
   "source": [
    "- 항상 가장 빈번한 클래스를 예측하여 얻을 수있는 정확도.\n",
    "- 이것은 항상 0/1을 예측하는 멍청한 모델이 \"null_accuracy\"%의 시간에 맞을 것이라는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwZOvjqfF8Bn",
    "outputId": "071b3f06-4bc8-4deb-ef9b-2d1f475f4d3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6509981851179674"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class BaseClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "    \n",
    "base_clf = BaseClassifier()\n",
    "cross_val_score(base_clf, X_train, y_train, cv=10, scoring=\"accuracy\").mean()\n",
    "\n",
    "\n",
    "# Method 2\n",
    "# calculate null accuracy (for binary / multi-class classification problems)\n",
    "# null_accuracy = y_train.value_counts().head(1) / len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY1q61cIGE8Z"
   },
   "source": [
    "### 분류 정확도\n",
    "(Classification Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EJJqV-DGHzR"
   },
   "source": [
    "분류 정확도 또는 정확도는 총 입력 샘플 수에 대한 올바른 예측 수의 비율입니다.  \n",
    "\n",
    "$$Accuracy = \\frac{Number\\ of\\ correct\\ predictions}{Total\\ number\\ of\\ predictions\\ made} = \\frac{TP + TN}{TP + TN + FP + FN}$$  \n",
    "![다운로드](https://user-images.githubusercontent.com/72365720/100689145-3b388380-33c7-11eb-9f61-aec4666ba452.png)  \n",
    "\n",
    "정확도 측정 항목을 사용하는 경우: 각 클래스에 속하는 샘플 수가 거의 동일한 경우  \n",
    "정확도 측정 항목을 사용하지 않는 경우: 하나의 클래스 만 대부분의 샘플을 보유 할 때.  \n",
    "<br>\n",
    "**예**:  \n",
    "훈련 세트에 클래스 A의 샘플이 98 %이고 클래스 B의 샘플이 2 %라고 가정합니다. 그러면 우리 모델은 클래스 A에 속하는 모든 훈련 샘플을 간단히 예측하여 98 %의 훈련 정확도를 쉽게 얻을 수 있습니다.  \n",
    "동일한 모델이 클래스 A의 60 % 샘플과 클래스 B의 40 % 샘플이있는 테스트 세트에서 테스트되면 테스트 정확도가 60 %로 떨어집니다. 분류 정확도는 우리에게 높은 정확도를 달성한다는 잘못된 감각을 줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2yWalnLG41C",
    "outputId": "dc232233-5e5e-4068-9f60-be8a4d3b6275"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7797035692679977, 0.611222020568663, 0.7606473079249849)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 계산\n",
    "\n",
    "acc_logreg = cross_val_score(clf_logreg, X_train, y_train, cv = cv, scoring = 'accuracy').mean()\n",
    "acc_SGD = cross_val_score(clf_SGD, X_train, y_train, cv = cv, scoring = 'accuracy').mean()\n",
    "acc_rfc = cross_val_score(clf_rfc, X_train, y_train, cv = cv, scoring = 'accuracy').mean()\n",
    "\n",
    "acc_logreg, acc_SGD, acc_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--DMNe8bHjOg"
   },
   "source": [
    "### 로그 손실 / 로그 손실 / 로지스틱 손실 / 교차 엔트로피 손실"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNPjI1cMHk5p"
   },
   "source": [
    "- 로그 손실로 작업 할 때 분류기는 모든 샘플에 대해 각 클래스에 확률을 할당해야합니다.\n",
    "- 로그 손실은 실제 레이블과 비교하고 잘못된 분류에 페널티를 적용하여 모델 확률의 불확실성을 측정합니다.\n",
    "- 로그 손실은 둘 이상의 레이블에 대해서만 정의됩니다.\n",
    "- 로그 손실은 예측 확률이 향상됨에 따라 점차 감소하므로 로그 손실이 0에 가까울수록 정확도가 높아지고 로그 손실이 0에서 멀어지면 정확도가 낮아집니다.\n",
    "- 로그 손실은 (0, ∞] 범위에 있습니다.\n",
    "\n",
    "M 클래스에 속하는 N 개의 샘플이 있다고 가정하면 로그 손실은 다음과 같이 계산됩니다.  \n",
    "$$ Log\\ Loss = \\frac{-1}{N} \\sum_{i=1}^{N} \\sum_{i=1}^{M}  y_{ij} * \\log(\\hat{y_{ij}})$$   \n",
    "- $y_{ij}$ ,샘플 i가 클래스 j에 속하는지 여부를 나타냅니다.\n",
    "- $p_{ij}$ ,샘플 i가 클래스 j에 속하는 확률을 나타냅니다.\n",
    "\n",
    "음수 부호 부정  $\\log(\\hat{y_{ij}})$  항상 음수 인 출력.  $\\hat{y_{ij}}$  확률 (0-1)을 출력하고,  $\\log(x)$  0 <x <1 인 경우 음수입니다.  \n",
    "\n",
    "**예**:  \n",
    "학습 레이블은 0과 1이지만 학습 예측은 0.4, 0.6, 0.89 등입니다. 모델의 오류 측정 값을 계산하기 위해 0.5보다 큰 값을 갖는 모든 관측 값을 1로 분류 할 수 있습니다. 우리는 오 분류를 증가시킬 위험이 높습니다. 확률이 0.4, 0.45, 0.49 인 많은 값이 1의 참값을 가질 수 있기 때문입니다.  \n",
    "이것이 logLoss가 등장하는 곳입니다.  \n",
    "이제 LogLoss의 공식을 자세히 살펴 보겠습니다. 값에 대한 4 가지 주요 사례가있을 수 있습니다. $y_{ij}$  과  $p_{ij}$ \n",
    "- 사례 1 :  $y_{ij}$j =1 ,  $p_{ij}$  = 높음\n",
    "- 사례 2 :  $y_{ij}$ =1 ,  $p_{ij}$  = 낮음\n",
    "- 사례 3 :  $y_{ij}$ =0 ,  $p_{ij}$  = 낮음\n",
    "- 사례 4 :  $y_{ij}$ =0 ,  $p_{ij}$  = 높음\n",
    "\n",
    "LogLoss는 불확실성을 어떻게 측정합니까?  \n",
    "케이스 1과 케이스 3이 더 많이있는 경우 로그 로스 공식 내부의 합계 (및 평균)는 케이스 2와 케이스 4가 추가 된 경우에 비해 훨씬 더 커질 것입니다. 이제이 값은 좋은 예측을 나타내는 Case 1 및 Case 3만큼 큽니다. (-1)을 곱하면 값을 가능한 한 작게 만듭니다. 이것은 이제 직관적으로 의미합니다.-값이 작을수록 모델이 더 좋습니다. 즉, 로그 손실이 더 작고, 모델이 더 좋습니다. 즉, 불확실성이 더 작고, 모델이 더 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rN1WRDcuMarb",
    "outputId": "d4c2ebf7-22ec-4914-dfed-1375486959c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.48368646454082465, -0.6383384003043665, -0.4664817973667718)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logloss 계산\n",
    "\n",
    "logloss_logreg = cross_val_score(clf_logreg, X_train, y_train, cv = cv, scoring = 'neg_log_loss').mean()\n",
    "logloss_rfc = cross_val_score(clf_rfc, X_train, y_train, cv = cv, scoring = 'neg_log_loss').mean()\n",
    "\n",
    "# SGDClassifier의 힌지 손실은 확률 추정을 지원하지 않습니다.\n",
    "# Scikit-learn의 CalibratedClassifierCV에서 SGDClassifier를 기본 추정기로 설정하여 확률 추정치를 생성 할 수 있습니다.\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "new_clf_SGD = CalibratedClassifierCV(clf_SGD)\n",
    "new_clf_SGD.fit(X_train, y_train)\n",
    "logloss_SGD = cross_val_score(new_clf_SGD, X_train, y_train, cv = cv, scoring = 'neg_log_loss').mean()\n",
    "\n",
    "logloss_logreg, logloss_SGD, logloss_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqtYV71rNIv5"
   },
   "source": [
    "### ROC 곡선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHEEaXsJNK2D"
   },
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yu7KV2ojNMgr"
   },
   "source": [
    "### 혼동 매트릭스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8ZNXvWqNOAT"
   },
   "source": [
    "### 분류 보고서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUlCh5DnNPkr"
   },
   "source": [
    "### 정밀도-재현율 트레이드 오프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hSK_OMPNVjS"
   },
   "source": [
    "### 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KFhNbsdNZdC"
   },
   "source": [
    "## 회귀 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQTO0XpbNaya"
   },
   "source": [
    "### 평균 절대 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjoWvQ8lNbzq"
   },
   "source": [
    "### 평균 제곱 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6HNlEiWNdPz"
   },
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJbd336nNe4p"
   },
   "source": [
    "### 평균 제곱근 로그 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICsaiNXzNgVy"
   },
   "source": [
    "### R_ 제곱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jll1XVZBNhtK"
   },
   "source": [
    "### 조정 된 R- 제곱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7OgvnLCNkQa"
   },
   "source": [
    "## NLP 메트릭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKruYNsTNosL"
   },
   "source": [
    "## 보너스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIpBb8mqNqiT"
   },
   "source": [
    "### 다중 클래스 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQq9MZZSNttL"
   },
   "source": [
    "### 다중 라벨 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPueq3eyNvF7"
   },
   "source": [
    "### 다중 출력 분류"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "kaggle_how-to-choose-right-metric-for-evaluating-ml-model_vipulgandhi.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
